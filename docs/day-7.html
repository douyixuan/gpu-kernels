<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Day 7 - GPU Kernels Learning Journey</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            color: #333;
            background: #f5f5f5;
        }
        
        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 2rem 1rem;
            text-align: center;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        
        .header h1 {
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
        }
        
        .header .subtitle {
            font-size: 1.1rem;
            opacity: 0.9;
        }
        
        .nav {
            background: white;
            padding: 1rem;
            box-shadow: 0 2px 5px rgba(0,0,0,0.05);
            position: sticky;
            top: 0;
            z-index: 100;
        }
        
        .nav-content {
            max-width: 1200px;
            margin: 0 auto;
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 1rem;
        }
        
        .nav a {
            color: #667eea;
            text-decoration: none;
            padding: 0.5rem 1rem;
            border-radius: 5px;
            transition: all 0.3s;
        }
        
        .nav a:hover {
            background: #667eea;
            color: white;
        }
        
        .container {
            max-width: 1200px;
            margin: 2rem auto;
            padding: 0 1rem;
        }
        
        .description {
            background: white;
            padding: 2rem;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.05);
            margin-bottom: 2rem;
        }
        
        .description h2 {
            color: #667eea;
            margin-bottom: 1rem;
            border-bottom: 2px solid #667eea;
            padding-bottom: 0.5rem;
        }
        
        .description pre {
            background: #f5f5f5;
            padding: 1rem;
            border-radius: 5px;
            overflow-x: auto;
        }
        
        .file-section {
            background: white;
            margin-bottom: 2rem;
            border-radius: 10px;
            overflow: hidden;
            box-shadow: 0 2px 10px rgba(0,0,0,0.05);
        }
        
        .file-section h3 {
            background: #667eea;
            color: white;
            padding: 1rem;
            margin: 0;
        }
        
        .file-section pre {
            margin: 0;
            border-radius: 0;
        }
        
        .file-section code {
            display: block;
            padding: 1.5rem;
            max-height: 600px;
            overflow: auto;
        }
        
        .no-files {
            text-align: center;
            padding: 3rem;
            color: #999;
            font-style: italic;
        }
        
        @media (max-width: 768px) {
            .header h1 {
                font-size: 1.8rem;
            }
            
            .nav-content {
                flex-direction: column;
                text-align: center;
            }
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>Day 7</h1>
        <div class="subtitle">GPU Kernels Learning Journey</div>
    </div>
    
    <nav class="nav">
        <div class="nav-content">
            <a href="index.html">← Back to Index</a>
            <div>
                <a href="day-6.html">← Day 6</a>
                <a href="day-8.html">Day 8 →</a>
            </div>
        </div>
    </nav>
    
    <div class="container">
        <div class="description">
            <h2>Description</h2>
            <div class="desc-content">
### File: `one_d_convolution.cu`
**Summary:**  
Implemented a simple 1D convolution algorithm using CUDA. This involved sliding a kernel (or filter) over an input array and computing the weighted sum of elements. Each thread was assigned to compute the convolution at a specific position in the output array.  

**Learned:**  
- Basics of 1D convolution in parallel, including mapping threads to positions in the output array.
- How to handle boundary conditions (halo cells) when the kernel partially overlaps the input array bounds.
- Importance of memory layout and contiguous access for kernel weights and input arrays to maximize performance.

---

### File: `one_d_convolution_with_tiling.cu`
**Summary:**  
Implemented an optimized version of the 1D convolution algorithm using tiling and shared memory. Divided the input array into tiles and loaded data into shared memory, minimizing global memory accesses for better performance. Used halo cells to handle edge cases where kernel overlap extended into neighboring tiles.  

**Learned:**  
- Tiling in CUDA: Dividing input data into manageable chunks and leveraging shared memory to reduce global memory latency.
- Use of **halo cells** to ensure correctness at tile boundaries during convolution.
- How to balance computation and memory usage in tiled algorithms to improve performance.
- Proper synchronization of threads within a block (using `__syncthreads()`) to ensure data consistency in shared memory.

---
### File: `2d_convolution_with_tiling.cu`  
**Summary:**  
Implemented a 2D convolution algorithm with tiling optimization using CUDA. Divided the input matrix into tiles and leveraged shared memory to minimize global memory accesses, ensuring efficient computation of the convolution kernel across the matrix. Handled boundary conditions using halo cells to process edges and corners correctly.  

**Learned:**  
- Extended tiling techniques from 1D to 2D data structures for efficient parallel computation.  
- Optimized global memory access by using shared memory for each tile.  
- Synchronization of threads for consistent shared memory usage within a block (`__syncthreads()` for proper execution order).  
- Efficient handling of edge cases and boundary cells in 2D convolution.  

--- 

### Reading:  
- Read **Chapter 7** of the PMPP book.  
  - Learned about parallel patterns for convolution, including basic algorithms, memory optimizations with constant and shared memory, and tiling techniques with halo cells for 1D and 2D convolution.
            </div>
        </div>
        
        <h2 style="margin-bottom: 1rem; color: #667eea;">Code Files</h2>

    <div class="file-section">
        <h3>one_d_convolution.cu</h3>
        <pre><code class="language-cuda">#include &lt;iostream&gt;
#include &lt;cuda_runtime.h&gt;
#define Mask_width 5  
__constant__ float M[Mask_width];
__global__ void oned_convolution_kernel(const float* A,float* C,int n ){
//without tiling 
int threadId=threadIdx.x;
int i=blockDim.x*blockIdx.x+threadId;

if (i&lt;n){
float result=0.0f;
for (int k=-1*Mask_width/2;k&lt;Mask_width/2+1;k++) {
  printf("%.i",k);
  if (i+k&gt;=0 &amp;&amp; i+k&lt;n) {
    
  result+=A[i+k]*M[k+Mask_width/2];
  
}}
C[i]=result;

}
}





// Host function to check for CUDA errors
void checkCudaError(const char* message) {
    cudaError_t error = cudaGetLastError();
    if (error != cudaSuccess) {
        std::cerr &lt;&lt; message &lt;&lt; " - CUDA Error: " &lt;&lt; cudaGetErrorString(error) &lt;&lt; std::endl;
        exit(EXIT_FAILURE);
    }
}


int main(){
 
  int n=10;
  float A[n],C[n];
  float d_M[Mask_width];
  
   for (int i=0; i&lt;Mask_width;i++){
    d_M[i]=i;

  }
  for (int i=0; i&lt;n;i++){
    A[i]=i;

  }

  float *d_a,*d_c;
  cudaMalloc(&amp;d_a,n*sizeof(float));
  cudaMalloc(&amp;d_c,n*sizeof(float));
  cudaMemcpy(d_a,A,n*sizeof(float),cudaMemcpyHostToDevice);
  checkCudaError("Failed to copy input data to device");
  cudaMemcpyToSymbol(M,d_M,Mask_width*sizeof(float));
  checkCudaError("Failed to copy mask data to device");
  dim3 dimBlock(32);
  dim3 dimGrid((n + dimBlock.x - 1) / dimBlock.x);
  oned_convolution_kernel&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(d_a,d_c,n);
  checkCudaError("Failed to execute the kernel");
  cudaDeviceSynchronize();
  cudaMemcpy(C,d_c,n*sizeof(float),cudaMemcpyDeviceToHost);
checkCudaError("Failed to copy output data to host");
  cudaFree(d_a);
  cudaFree(d_c);
  

  //printing the results
  printf("A:\n");
  for (int i=0; i&lt;n;i++){
    printf("%.2f ", A[i]);

  }
  printf("\n");
   printf("\nd_m:\n");
    for (int i = 0; i &lt; Mask_width; i++) {

            printf("%.2f ", d_M[i]);

    }
  printf("\n");
  printf("\nC:\n");
    for (int i = 0; i &lt; n; i++) {

            printf("%.2f ", C[i]);

    }
  printf("\n");
}</code></pre>
    </div>

    <div class="file-section">
        <h3>2d_convolution_with_tiling.cu</h3>
        <pre><code class="language-cuda">#include &lt;stdio.h&gt;
#include &lt;iostream&gt;

// I'm assuming that the mask and the matrix to be square for simplicity
#define Mask_width 5
#define shared_size (32 + Mask_width - 1)
__constant__ float M[Mask_width][Mask_width];

__global__ void twod_convolution_kernel(const float* A, float* C, int n) {
    int threadx = threadIdx.x;
    int thready = threadIdx.y;
    int i = blockDim.x * blockIdx.x + threadx;
    int j = blockDim.y * blockIdx.y + thready;
    
    __shared__ float S_A[shared_size][shared_size];

    // Load main data
    if ((i &lt; n) &amp;&amp; (j &lt; n)) {
        S_A[threadx + Mask_width/2][thready + Mask_width/2] = A[i*n+j];
    }

    // Load left halo
    if (threadx &lt; Mask_width/2) {
        int left_idx = blockIdx.x * blockDim.x - (Mask_width/2) + threadx;
        if (left_idx &gt;= 0 &amp;&amp; j &lt; n) {
            S_A[threadx][thready + Mask_width/2] = A[left_idx*n+j];
        }
        else {
            S_A[threadx][thready + Mask_width/2] = 0.0f;
        }
    }

    // Load right halo
    if (threadx &lt; Mask_width/2) {
        int right_idx = blockIdx.x * blockDim.x + blockDim.x + threadx;
        if (right_idx &lt; n &amp;&amp; j &lt; n) {
            S_A[threadx + blockDim.x + Mask_width/2][thready + Mask_width/2] = A[right_idx*n+j];
        }
        else {
            S_A[threadx + blockDim.x + Mask_width/2][thready + Mask_width/2] = 0.0f;
        }
    }

    // Load top halo
    if (thready &lt; Mask_width/2) {
        int top_idy = j - (Mask_width/2) + thready;
        if (top_idy &gt;= 0 &amp;&amp; i &lt; n) {
            S_A[threadx + Mask_width/2][thready] = A[i*n+top_idy];
        }
        else {
            S_A[threadx + Mask_width/2][thready] = 0.0f;
        }
    }

    // Load bottom halo
    if (thready &lt; Mask_width/2) {
        int bottom_idy = j + blockDim.y + thready;
        if (bottom_idy &lt; n &amp;&amp; i &lt; n) {
            S_A[threadx + Mask_width/2][thready + blockDim.y + Mask_width/2] = A[i*n+bottom_idy];
        }
        else {
            S_A[threadx + Mask_width/2][thready + blockDim.y + Mask_width/2] = 0.0f;
        }
    }

    __syncthreads();

    if ((i &lt; n) &amp;&amp; (j &lt; n)) {
        float result = 0.0f;
        for (int k = 0; k &lt; Mask_width; k++) {
            for (int x = 0; x &lt; Mask_width; x++) {
                result += S_A[threadx + k][thready + x] * M[k][x];
            }
        }
        C[i*n+j] = result;
    }
}

void checkCudaError(const char* message) {
    cudaError_t error = cudaGetLastError();
    if (error != cudaSuccess) {
        fprintf(stderr, "%s - CUDA Error: %s\n", message, cudaGetErrorString(error));
        exit(EXIT_FAILURE);
    }
}

int main() {
    int n = 10;
    float *h_A = (float*)malloc(n * n * sizeof(float));
    float *h_C = (float*)malloc(n * n * sizeof(float));
    float d_M[Mask_width][Mask_width];

    for (int i = 0; i &lt; Mask_width; i++) {
        for (int j = 0; j &lt; Mask_width; j++) {
            d_M[i][j] = 5;
        }
    }

    for (int i = 0; i &lt; n; i++) {
        for (int j = 0; j &lt; n; j++) {
            h_A[i*n + j] = 3;
        }
    }

    float *d_a, *d_c;
    cudaMalloc(&amp;d_a, n*n*sizeof(float));
    cudaMalloc(&amp;d_c, n*n*sizeof(float));
    cudaMemcpy(d_a, h_A, n*n*sizeof(float), cudaMemcpyHostToDevice);
    checkCudaError("Failed to copy input data to device");
    cudaMemcpyToSymbol(M, d_M, Mask_width*Mask_width*sizeof(float));
    checkCudaError("Failed to copy mask data to device");

    dim3 dimBlock(32, 32);
    dim3 dimGrid((n + dimBlock.x - 1) / dimBlock.x, (n + dimBlock.y - 1) / dimBlock.y);
    twod_convolution_kernel&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(d_a, d_c, n);
    checkCudaError("Failed to execute the kernel");
    
    cudaDeviceSynchronize();
    cudaMemcpy(h_C, d_c, n*n*sizeof(float), cudaMemcpyDeviceToHost);
    checkCudaError("Failed to copy output data to host");

    // Print results
    printf("Results:\n");
    for (int i = 0; i &lt; n; i++) {
        for (int j = 0; j &lt; n; j++) {
            printf("%.2f ", h_C[i*n + j]);
        }
        printf("\n");
    }

    // Clean up
    cudaFree(d_a);
    cudaFree(d_c);
    free(h_A);
    free(h_C);

    return 0;
}

</code></pre>
    </div>

    <div class="file-section">
        <h3>one_d_convolution_with_tiling.cu</h3>
        <pre><code class="language-cuda">#include &lt;iostream&gt;
#include &lt;cuda_runtime.h&gt;
#define Mask_width 5  
__constant__ float M[Mask_width];

__global__ void oned_convolution_tiling_kernel(const float* A, float* C, int n) {
    int threadId = threadIdx.x;
    int i = blockDim.x * blockIdx.x + threadId;
    
    __shared__ float S_A[32 + Mask_width - 1];
    
    // Load main data
    if (i &lt; n) {
        S_A[threadId + Mask_width/2] = A[i];
    }
    
    // Load left halo
    if (threadId &lt; Mask_width/2) {
        int left_idx = blockIdx.x * blockDim.x - (Mask_width/2) + threadId;
        if (left_idx &gt;= 0) {
            S_A[threadId] = A[left_idx];
        }
        else {
            S_A[threadId] = 0.0f;
        }
    }
    
    // Load right halo
    if (threadId &lt; Mask_width/2) {
        int right_idx = blockIdx.x * blockDim.x + blockDim.x + threadId;
        if (right_idx &lt; n) {
            S_A[threadId + blockDim.x + Mask_width/2] = A[right_idx];
        }
        else {
            S_A[threadId + blockDim.x + Mask_width/2] = 0.0f;
        }
    }
    
    __syncthreads();
    
    if (i &lt; n) {
        float result = 0.0f;
        for (int k = 0; k &lt; Mask_width; k++) {
            int idx = threadId + k;
            if ((i + k - Mask_width/2) &gt;= 0 &amp;&amp; (i + k - Mask_width/2) &lt; n) {
                result += S_A[idx] * M[k];
            }
        }
        C[i] = result;
    }
}




// Host function to check for CUDA errors
void checkCudaError(const char* message) {
    cudaError_t error = cudaGetLastError();
    if (error != cudaSuccess) {
        std::cerr &lt;&lt; message &lt;&lt; " - CUDA Error: " &lt;&lt; cudaGetErrorString(error) &lt;&lt; std::endl;
        exit(EXIT_FAILURE);
    }
}


int main(){
 
  int n=10;
  float A[n],C[n];
  float d_M[Mask_width];
  
   for (int i=0; i&lt;Mask_width;i++){
    d_M[i]=i;

  }
  for (int i=0; i&lt;n;i++){
    A[i]=i;

  }

  float *d_a,*d_c;
  cudaMalloc(&amp;d_a,n*sizeof(float));
  cudaMalloc(&amp;d_c,n*sizeof(float));
  cudaMemcpy(d_a,A,n*sizeof(float),cudaMemcpyHostToDevice);
  checkCudaError("Failed to copy input data to device");
  cudaMemcpyToSymbol(M,d_M,Mask_width*sizeof(float));
  checkCudaError("Failed to copy mask data to device");
  dim3 dimBlock(32);
  dim3 dimGrid((n + dimBlock.x - 1) / dimBlock.x);
  oned_convolution_tiling_kernel&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(d_a,d_c,n);
  checkCudaError("Failed to execute the kernel");
  cudaDeviceSynchronize();
  cudaMemcpy(C,d_c,n*sizeof(float),cudaMemcpyDeviceToHost);
checkCudaError("Failed to copy output data to host");
  cudaFree(d_a);
  cudaFree(d_c);
  

  //printing the results
  printf("A:\n");
  for (int i=0; i&lt;n;i++){
    printf("%.2f ", A[i]);

  }
  printf("\n");
   printf("\nd_m:\n");
    for (int i = 0; i &lt; Mask_width; i++) {

            printf("%.2f ", d_M[i]);

    }
  printf("\n");
  printf("\nC:\n");
    for (int i = 0; i &lt; n; i++) {

            printf("%.2f ", C[i]);

    }
  printf("\n");
}</code></pre>
    </div>

    </div>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-c.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-cpp.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-markdown.min.js"></script>
</body>
</html>