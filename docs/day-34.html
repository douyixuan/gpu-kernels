<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Day 34 - GPU Kernels Learning Journey</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            color: #333;
            background: #f5f5f5;
        }
        
        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 2rem 1rem;
            text-align: center;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        
        .header h1 {
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
        }
        
        .header .subtitle {
            font-size: 1.1rem;
            opacity: 0.9;
        }
        
        .nav {
            background: white;
            padding: 1rem;
            box-shadow: 0 2px 5px rgba(0,0,0,0.05);
            position: sticky;
            top: 0;
            z-index: 100;
        }
        
        .nav-content {
            max-width: 1200px;
            margin: 0 auto;
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 1rem;
        }
        
        .nav a {
            color: #667eea;
            text-decoration: none;
            padding: 0.5rem 1rem;
            border-radius: 5px;
            transition: all 0.3s;
        }
        
        .nav a:hover {
            background: #667eea;
            color: white;
        }
        
        .container {
            max-width: 1200px;
            margin: 2rem auto;
            padding: 0 1rem;
        }
        
        .description {
            background: white;
            padding: 2rem;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.05);
            margin-bottom: 2rem;
        }
        
        .description h2 {
            color: #667eea;
            margin-bottom: 1rem;
            border-bottom: 2px solid #667eea;
            padding-bottom: 0.5rem;
        }
        
        .description pre {
            background: #f5f5f5;
            padding: 1rem;
            border-radius: 5px;
            overflow-x: auto;
        }
        
        .file-section {
            background: white;
            margin-bottom: 2rem;
            border-radius: 10px;
            overflow: hidden;
            box-shadow: 0 2px 10px rgba(0,0,0,0.05);
        }
        
        .file-section h3 {
            background: #667eea;
            color: white;
            padding: 1rem;
            margin: 0;
        }
        
        .file-section pre {
            margin: 0;
            border-radius: 0;
        }
        
        .file-section code {
            display: block;
            padding: 1.5rem;
            max-height: 600px;
            overflow: auto;
        }
        
        .no-files {
            text-align: center;
            padding: 3rem;
            color: #999;
            font-style: italic;
        }
        
        @media (max-width: 768px) {
            .header h1 {
                font-size: 1.8rem;
            }
            
            .nav-content {
                flex-direction: column;
                text-align: center;
            }
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>Day 34</h1>
        <div class="subtitle">GPU Kernels Learning Journey</div>
    </div>
    
    <nav class="nav">
        <div class="nav-content">
            <a href="index.html">← Back to Index</a>
            <div>
                <a href="day-33.html">← Day 33</a>
                <a href="day-35.html">Day 35 →</a>
            </div>
        </div>
    </nav>
    
    <div class="container">
        <div class="description">
            <h2>Description</h2>
            <div class="desc-content">
### Files: `vec_add_cpu.c`, `vec_add_gpu.cu`, `benchmark.py`
**Summary:**  

Today I  compared the performance of vector addition implemented using two different approaches:
CPU with MPI and Loop Unrolling - Parallelized across multiple CPU cores using MPI.
GPU with CUDA - Executed on a GPU for massive parallelism.
The script runs performance tests on different input sizes and generates a log-log scale plot comparing execution times.
            </div>
        </div>
        
        <h2 style="margin-bottom: 1rem; color: #667eea;">Code Files</h2>

    <div class="file-section">
        <h3>benchmark.py</h3>
        <pre><code class="language-python">import subprocess
import numpy as np
import matplotlib.pyplot as plt

# Define test sizes
sizes = [10**i for i in range(1, 10)]  # 10, 100, 1000, ..., 1 billion
cpu_times = []
gpu_times = []

# Compile CPU and GPU programs
subprocess.run("mpicc -o vec_add_cpu vec_add_cpu.c -O3", shell=True, check=True)
subprocess.run("nvcc -o vec_add_gpu vec_add_gpu.cu -O3", shell=True, check=True)

for size in sizes:
    print(f"Running for size: {size}")
    
    # Run MPI CPU version
    result_cpu = subprocess.run(
        f"mpirun --oversubscribe --allow-run-as-root -np 4 ./vec_add_cpu {size}",
        shell=True, capture_output=True, text=True
    )
    
    # Debugging output
    print("CPU Output:", result_cpu.stdout)
    print("Error (if any):", result_cpu.stderr)
    
    output = result_cpu.stdout.strip().split()
    if len(output) &gt;= 2:
        cpu_time = float(output[-2])  # Extract time if available
    else:
        print("Error: Unexpected CPU output format -&gt;", result_cpu.stdout)
        cpu_time = float('inf')  # Assign a large value to indicate failure
    cpu_times.append(cpu_time)
    
    # Run CUDA GPU version
    result_gpu = subprocess.run(
        f"./vec_add_gpu {size}", shell=True, capture_output=True, text=True
    )
    
    # Debugging output
    print("GPU Output:", result_gpu.stdout)
    print("Error (if any):", result_gpu.stderr)
    
    output = result_gpu.stdout.strip().split()
    if len(output) &gt;= 2:
        gpu_time = float(output[-2])  # Extract time if available
    else:
        print("Error: Unexpected GPU output format -&gt;", result_gpu.stdout)
        gpu_time = float('inf')  # Assign a large value to indicate failure
    gpu_times.append(gpu_time)

# Plot results
plt.figure(figsize=(10, 6))
plt.plot(sizes, cpu_times, marker='o', label='CPU (MPI + Unrolling)')
plt.plot(sizes, gpu_times, marker='s', label='GPU (CUDA)')
plt.xscale('log')
plt.yscale('log')
plt.xlabel("Input Size (log scale)")
plt.ylabel("Execution Time (ms, log scale)")
plt.legend()
plt.grid()
plt.title("Performance Comparison: CPU vs. GPU for Vector Addition")
plt.show()</code></pre>
    </div>

    <div class="file-section">
        <h3>vec_add_gpu.cu</h3>
        <pre><code class="language-cuda">#include &lt;stdio.h&gt;
#include &lt;cuda.h&gt;

#define UNROLL_FACTOR 4

__global__ void vector_add(double *A, double *B, double *C, int N) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int limit = N - (N % UNROLL_FACTOR);

    for (; i &lt; limit; i += blockDim.x * gridDim.x) {
        C[i] = A[i] + B[i];
        C[i+1] = A[i+1] + B[i+1];
        C[i+2] = A[i+2] + B[i+2];
        C[i+3] = A[i+3] + B[i+3];
    }

    for (; i &lt; N; i++) {
        C[i] = A[i] + B[i];
    }
}

int main(int argc, char **argv) {
    int N = atoi(argv[1]);
    double *h_A, *h_B, *h_C;
    double *d_A, *d_B, *d_C;

    size_t size = N * sizeof(double);
    h_A = (double*) malloc(size);
    h_B = (double*) malloc(size);
    h_C = (double*) malloc(size);

    for (int i = 0; i &lt; N; i++) {
        h_A[i] = i;
        h_B[i] = i * 2;
    }

    cudaMalloc((void**)&amp;d_A, size);
    cudaMalloc((void**)&amp;d_B, size);
    cudaMalloc((void**)&amp;d_C, size);

    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);

    int threadsPerBlock = 256;
    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;

    cudaEvent_t start, stop;
    cudaEventCreate(&amp;start);
    cudaEventCreate(&amp;stop);
    cudaEventRecord(start);

    vector_add&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(d_A, d_B, d_C, N);
    
    cudaEventRecord(stop);
    cudaEventSynchronize(stop);

    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);

    float elapsedTime;
    cudaEventElapsedTime(&amp;elapsedTime, start, stop);
    printf("GPU (CUDA): %f ms\n", elapsedTime);

    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);
    free(h_A); free(h_B); free(h_C);

    return 0;
}
</code></pre>
    </div>

    <div class="file-section">
        <h3>vec_add_cpu.c</h3>
        <pre><code class="language-c">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;mpi.h&gt;
#include &lt;time.h&gt;

#define UNROLL_FACTOR 4  // Loop unrolling factor

void vector_add(double *A, double *B, double *C, int size) {
    int i, limit = size - (size % UNROLL_FACTOR);
    for (i = 0; i &lt; limit; i += UNROLL_FACTOR) {
        C[i]   = A[i]   + B[i];
        C[i+1] = A[i+1] + B[i+1];
        C[i+2] = A[i+2] + B[i+2];
        C[i+3] = A[i+3] + B[i+3];
    }
    for (; i &lt; size; i++) {
        C[i] = A[i] + B[i];
    }
}

int main(int argc, char **argv) {
    int rank, size, N = atoi(argv[1]);  // Take vector size as argument
    MPI_Init(&amp;argc, &amp;argv);
    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);
    MPI_Comm_size(MPI_COMM_WORLD, &amp;size);

    int chunk_size = N / size;
    int start = rank * chunk_size;
    int end = (rank == size - 1) ? N : start + chunk_size;

    double *A = (double*) malloc(chunk_size * sizeof(double));
    double *B = (double*) malloc(chunk_size * sizeof(double));
    double *C = (double*) malloc(chunk_size * sizeof(double));

    for (int i = 0; i &lt; chunk_size; i++) {
        A[i] = i + rank;
        B[i] = i - rank;
    }

    double t1 = MPI_Wtime();
    vector_add(A, B, C, chunk_size);
    double t2 = MPI_Wtime();

    if (rank == 0) {
        printf("CPU (MPI + Unrolling): %lf miliseconds\n", (t2 - t1)*1000.0);
    }

    free(A); free(B); free(C);
    MPI_Finalize();
    return 0;
}
</code></pre>
    </div>

    </div>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-c.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-cpp.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-markdown.min.js"></script>
</body>
</html>