<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Day 48 - GPU Kernels Learning Journey</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            color: #333;
            background: #f5f5f5;
        }
        
        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 2rem 1rem;
            text-align: center;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        
        .header h1 {
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
        }
        
        .header .subtitle {
            font-size: 1.1rem;
            opacity: 0.9;
        }
        
        .nav {
            background: white;
            padding: 1rem;
            box-shadow: 0 2px 5px rgba(0,0,0,0.05);
            position: sticky;
            top: 0;
            z-index: 100;
        }
        
        .nav-content {
            max-width: 1200px;
            margin: 0 auto;
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 1rem;
        }
        
        .nav a {
            color: #667eea;
            text-decoration: none;
            padding: 0.5rem 1rem;
            border-radius: 5px;
            transition: all 0.3s;
        }
        
        .nav a:hover {
            background: #667eea;
            color: white;
        }
        
        .container {
            max-width: 1200px;
            margin: 2rem auto;
            padding: 0 1rem;
        }
        
        .description {
            background: white;
            padding: 2rem;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.05);
            margin-bottom: 2rem;
        }
        
        .description h2 {
            color: #667eea;
            margin-bottom: 1rem;
            border-bottom: 2px solid #667eea;
            padding-bottom: 0.5rem;
        }
        
        .description pre {
            background: #f5f5f5;
            padding: 1rem;
            border-radius: 5px;
            overflow-x: auto;
        }
        
        .file-section {
            background: white;
            margin-bottom: 2rem;
            border-radius: 10px;
            overflow: hidden;
            box-shadow: 0 2px 10px rgba(0,0,0,0.05);
        }
        
        .file-section h3 {
            background: #667eea;
            color: white;
            padding: 1rem;
            margin: 0;
        }
        
        .file-section pre {
            margin: 0;
            border-radius: 0;
        }
        
        .file-section code {
            display: block;
            padding: 1.5rem;
            max-height: 600px;
            overflow: auto;
        }
        
        .no-files {
            text-align: center;
            padding: 3rem;
            color: #999;
            font-style: italic;
        }
        
        @media (max-width: 768px) {
            .header h1 {
                font-size: 1.8rem;
            }
            
            .nav-content {
                flex-direction: column;
                text-align: center;
            }
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>Day 48</h1>
        <div class="subtitle">GPU Kernels Learning Journey</div>
    </div>
    
    <nav class="nav">
        <div class="nav-content">
            <a href="index.html">← Back to Index</a>
            <div>
                <a href="day-47.html">← Day 47</a>
                <a href="day-49.html">Day 49 →</a>
            </div>
        </div>
    </nav>
    
    <div class="container">
        <div class="description">
            <h2>Description</h2>
            <div class="desc-content">
<h3>Files: <code>lbfgs.cu</code></h3>
<p>I implemented a CUDA-based version of the L-BFGS optimization algorithm, leveraging GPU parallelism to accelerate the two-loop recursion for search direction computation. The implementation includes custom CUDA kernels for parallel dot product computation, vector operations (subtraction, scaling, addition), and efficient memory management to minimize host-device communication. The search direction is computed using a simplified two-loop recursion, updating intermediate vectors based on correction pairs and scaling factors. By optimizing memory access and reducing redundant computations, this implementation enhances performance for large-scale optimization tasks in machine learning and scientific computing.</p>
            </div>
        </div>
        
        <h2 style="margin-bottom: 1rem; color: #667eea;">Code Files</h2>

    <div class="file-section">
        <h3>lbfgs.cu</h3>
        <pre><code class="language-cpp">#include &lt;cuda_runtime.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;math.h&gt;

// Kernel to compute dot product using shared memory reduction.
__global__ void dotProductKernel(const double* a, const double* b, double* result, int n) {
    __shared__ double cache[256];
    int tid = threadIdx.x + blockIdx.x * blockDim.x;
    int cacheIndex = threadIdx.x;
    double temp = 0.0;
    while(tid &lt; n) {
        temp += a[tid] * b[tid];
        tid += blockDim.x * gridDim.x;
    }
    cache[cacheIndex] = temp;
    __syncthreads();
    
    // Reduction in shared memory.
    for (int stride = blockDim.x/2; stride &gt; 0; stride /= 2) {
        if(cacheIndex &lt; stride)
            cache[cacheIndex] += cache[cacheIndex + stride];
        __syncthreads();
    }
    if(cacheIndex == 0)
        atomicAdd(result, cache[0]);
}

// Kernel for vector subtraction: a = a - scalar * b.
__global__ void vectorSubKernel(double* a, const double* b, double scalar, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if(idx &lt; n) {
        a[idx] -= scalar * b[idx];
    }
}

// Kernel for vector scaling: a = scalar * a.
__global__ void vectorScaleKernel(double* a, double scalar, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if(idx &lt; n) {
        a[idx] *= scalar;
    }
}

// Kernel for vector addition: a = a + scalar * b.
__global__ void vectorAddKernel(double* a, const double* b, double scalar, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if(idx &lt; n) {
        a[idx] += scalar * b[idx];
    }
}

// Helper function to launch a dot product kernel and retrieve result.
double gpuDot(const double* d_a, const double* d_b, int n) {
    double h_result = 0.0;
    double* d_result;
    cudaMalloc(&amp;d_result, sizeof(double));
    cudaMemset(d_result, 0, sizeof(double));

    int blockSize = 256;
    int gridSize = (n + blockSize - 1) / blockSize;
    dotProductKernel&lt;&lt;&lt;gridSize, blockSize&gt;&gt;&gt;(d_a, d_b, d_result, n);
    cudaMemcpy(&amp;h_result, d_result, sizeof(double), cudaMemcpyDeviceToHost);
    cudaFree(d_result);
    return h_result;
}

// Example: one iteration of simplified L-BFGS with a single correction pair.
int main() {
    const int n = 1024;       // dimension of the problem
    const int blockSize = 256;
    const int gridSize = (n + blockSize - 1) / blockSize;

    // Allocate host memory.
    double *h_x = (double*)malloc(n * sizeof(double));
    double *h_grad = (double*)malloc(n * sizeof(double));
    double *h_s = (double*)malloc(n * sizeof(double)); // previous step: s = x_{k+1} - x_k
    double *h_y = (double*)malloc(n * sizeof(double)); // difference in gradients: y = grad_{k+1} - grad_k

    // Initialize with dummy data.
    for (int i = 0; i &lt; n; i++) {
        h_x[i] = 1.0;       // initial parameter
        h_grad[i] = 0.5;    // current gradient
        h_s[i] = 0.1;       // example previous step
        h_y[i] = 0.2;       // example gradient difference
    }

    // Allocate device memory.
    double *d_x, *d_grad, *d_s, *d_y, *d_q, *d_r;
    cudaMalloc(&amp;d_x, n * sizeof(double));
    cudaMalloc(&amp;d_grad, n * sizeof(double));
    cudaMalloc(&amp;d_s, n * sizeof(double));
    cudaMalloc(&amp;d_y, n * sizeof(double));
    cudaMalloc(&amp;d_q, n * sizeof(double));
    cudaMalloc(&amp;d_r, n * sizeof(double));

    // Copy data to device.
    cudaMemcpy(d_x, h_x, n * sizeof(double), cudaMemcpyHostToDevice);
    cudaMemcpy(d_grad, h_grad, n * sizeof(double), cudaMemcpyHostToDevice);
    cudaMemcpy(d_s, h_s, n * sizeof(double), cudaMemcpyHostToDevice);
    cudaMemcpy(d_y, h_y, n * sizeof(double), cudaMemcpyHostToDevice);

    // -------- Two-loop recursion (simplified for m = 1) --------
    // 1. Set q = grad.
    cudaMemcpy(d_q, d_grad, n * sizeof(double), cudaMemcpyDeviceToDevice);

    // 2. Compute rho = 1 / dot(s, y)
    double dot_sy = gpuDot(d_s, d_y, n);
    double rho = 1.0 / dot_sy;

    // 3. Compute alpha = rho * dot(s, q)
    double dot_sq = gpuDot(d_s, d_q, n);
    double alpha = rho * dot_sq;

    // 4. Update q = q - alpha * y.
    vectorSubKernel&lt;&lt;&lt;gridSize, blockSize&gt;&gt;&gt;(d_q, d_y, alpha, n);

    // 5. Compute H0 = dot(s,y) / dot(y,y) (scalar for initial Hessian approximation).
    double dot_yy = gpuDot(d_y, d_y, n);
    double H0 = dot_sy / dot_yy;

    // 6. Set r = H0 * q. (scale q and store in r)
    cudaMemcpy(d_r, d_q, n * sizeof(double), cudaMemcpyDeviceToDevice);
    vectorScaleKernel&lt;&lt;&lt;gridSize, blockSize&gt;&gt;&gt;(d_r, H0, n);

    // 7. Compute beta = rho * dot(y, r)
    double dot_yr = gpuDot(d_y, d_r, n);
    double beta = rho * dot_yr;

    // 8. Update r = r + s * (alpha - beta)
    double scalar = (alpha - beta);
    vectorAddKernel&lt;&lt;&lt;gridSize, blockSize&gt;&gt;&gt;(d_r, d_s, scalar, n);

    // Now the search direction is given by: direction = -r.
    vectorScaleKernel&lt;&lt;&lt;gridSize, blockSize&gt;&gt;&gt;(d_r, -1.0, n);

    // -------- Update parameters: x_new = x + step * direction --------
    double step = 0.1;  // example step length (in practice, found via line search)
    vectorAddKernel&lt;&lt;&lt;gridSize, blockSize&gt;&gt;&gt;(d_x, d_r, step, n);

    // Copy the updated x back to host.
    cudaMemcpy(h_x, d_x, n * sizeof(double), cudaMemcpyDeviceToHost);

    // Print the first 10 updated parameters.
    printf("Updated parameters (first 10 values):\n");
    for (int i = 0; i &lt; 10; i++) {
        printf("x[%d] = %f\n", i, h_x[i]);
    }

    // Free device memory.
    cudaFree(d_x);
    cudaFree(d_grad);
    cudaFree(d_s);
    cudaFree(d_y);
    cudaFree(d_q);
    cudaFree(d_r);

    // Free host memory.
    free(h_x);
    free(h_grad);
    free(h_s);
    free(h_y);

    return 0;
}</code></pre>
    </div>

    </div>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-c.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-cpp.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-markdown.min.js"></script>
</body>
</html>