<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Day 66 - GPU Kernels Learning Journey</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            color: #333;
            background: #f5f5f5;
        }
        
        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 2rem 1rem;
            text-align: center;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        
        .header h1 {
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
        }
        
        .header .subtitle {
            font-size: 1.1rem;
            opacity: 0.9;
        }
        
        .nav {
            background: white;
            padding: 1rem;
            box-shadow: 0 2px 5px rgba(0,0,0,0.05);
            position: sticky;
            top: 0;
            z-index: 100;
        }
        
        .nav-content {
            max-width: 1200px;
            margin: 0 auto;
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 1rem;
        }
        
        .nav a {
            color: #667eea;
            text-decoration: none;
            padding: 0.5rem 1rem;
            border-radius: 5px;
            transition: all 0.3s;
        }
        
        .nav a:hover {
            background: #667eea;
            color: white;
        }
        
        .container {
            max-width: 1200px;
            margin: 2rem auto;
            padding: 0 1rem;
        }
        
        .description {
            background: white;
            padding: 2rem;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.05);
            margin-bottom: 2rem;
        }
        
        .description h2 {
            color: #667eea;
            margin-bottom: 1rem;
            border-bottom: 2px solid #667eea;
            padding-bottom: 0.5rem;
        }
        
        .description pre {
            background: #f5f5f5;
            padding: 1rem;
            border-radius: 5px;
            overflow-x: auto;
        }
        
        .file-section {
            background: white;
            margin-bottom: 2rem;
            border-radius: 10px;
            overflow: hidden;
            box-shadow: 0 2px 10px rgba(0,0,0,0.05);
        }
        
        .file-section h3 {
            background: #667eea;
            color: white;
            padding: 1rem;
            margin: 0;
        }
        
        .file-section pre {
            margin: 0;
            border-radius: 0;
        }
        
        .file-section code {
            display: block;
            padding: 1.5rem;
            max-height: 600px;
            overflow: auto;
        }
        
        .no-files {
            text-align: center;
            padding: 3rem;
            color: #999;
            font-style: italic;
        }
        
        @media (max-width: 768px) {
            .header h1 {
                font-size: 1.8rem;
            }
            
            .nav-content {
                flex-direction: column;
                text-align: center;
            }
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>Day 66</h1>
        <div class="subtitle">GPU Kernels Learning Journey</div>
    </div>
    
    <nav class="nav">
        <div class="nav-content">
            <a href="index.html">← Back to Index</a>
            <div>
                <a href="day-65.html">← Day 65</a>
                <a href="day-67.html">Day 67 →</a>
            </div>
        </div>
    </nav>
    
    <div class="container">
        <div class="description">
            <h2>Description</h2>
            <div class="desc-content">
<h3>Files: <code>swiglu.cu</code></h3>
<p>I re-implemented the Liger Triton kernel in native CUDA C++ to perform a SwiGLU operation and its backward pass for gradient computation, where the forward pass computes c = silu(a) × b (with silu(a) = a × sigmoid(a)) and the backward pass derives gradients for a and b by recomputing necessary activations; the code processes a 2D matrix in row‑major order using one CUDA block per row and one thread per column, and it includes memory allocation and kernel launches for both forward and backward passes with sample data.</p>
            </div>
        </div>
        
        <h2 style="margin-bottom: 1rem; color: #667eea;">Code Files</h2>

    <div class="file-section">
        <h3>swiglu.cu</h3>
        <pre><code class="language-cuda">#include &lt;iostream&gt;
#include &lt;cuda_runtime.h&gt;
#include &lt;cmath&gt;

__device__ inline float sigmoid(float x) {
    return 1.f / (1.f + expf(-x));
}

__device__ inline float silu(float x) {
    return x * sigmoid(x);
}

__global__ void swiglu_forward_kernel(const float *a, const float *b, float *c, int stride, int n_cols) {
    int row = blockIdx.x;
    int col = threadIdx.x;
    
    if (col &lt; n_cols) {
        int offset = row * stride + col;
        float a_val = a[offset];
        float b_val = b[offset];
        c[offset] = silu(a_val) * b_val;
    }
}

__global__ void swiglu_backward_kernel(float *dc, float *a, float *b, int stride, int n_cols) {
    int row = blockIdx.x;
    int col = threadIdx.x;
    
    if (col &lt; n_cols) {
        int offset = row * stride + col;
        float dc_val = dc[offset];
        float a_val = a[offset];
        float b_val = b[offset];
        
        float sig_a = sigmoid(a_val);
        float silu_a = a_val * sig_a;
        float db = dc_val * silu_a;
        float da = dc_val * (silu_a * (1.f - sig_a) + sig_a) * b_val;
        
        a[offset] = da;  
        b[offset] = db;
    }
}

int main() {
    const int n_rows = 4;
    const int n_cols = 8;
    const int stride = n_cols;
    const size_t num_elements = n_rows * stride;
    const size_t size = num_elements * sizeof(float);
    
    float h_a[num_elements];
    float h_b[num_elements];
    float h_c[num_elements];
    float h_dc[num_elements];
    
    for (int i = 0; i &lt; num_elements; i++) {
        h_a[i] = static_cast&lt;float&gt;(i) / 10.0f;
        h_b[i] = 1.0f;
        h_dc[i] = 1.0f;
    }
    
    float *d_a, *d_b, *d_c, *d_dc;
    cudaMalloc(&amp;d_a, size);
    cudaMalloc(&amp;d_b, size);
    cudaMalloc(&amp;d_c, size);
    cudaMalloc(&amp;d_dc, size);
    
    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_dc, h_dc, size, cudaMemcpyHostToDevice);
    
    swiglu_forward_kernel&lt;&lt;&lt;n_rows, n_cols&gt;&gt;&gt;(d_a, d_b, d_c, stride, n_cols);
    cudaDeviceSynchronize();
    
    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);
    
    std::cout &lt;&lt; "Forward pass result (c = silu(a)*b):" &lt;&lt; std::endl;
    for (int row = 0; row &lt; n_rows; row++) {
        for (int col = 0; col &lt; n_cols; col++) {
            std::cout &lt;&lt; h_c[row * stride + col] &lt;&lt; " ";
        }
        std::cout &lt;&lt; std::endl;
    }
    
    swiglu_backward_kernel&lt;&lt;&lt;n_rows, n_cols&gt;&gt;&gt;(d_dc, d_a, d_b, stride, n_cols);
    cudaDeviceSynchronize();
    
    cudaMemcpy(h_a, d_a, size, cudaMemcpyDeviceToHost);
    cudaMemcpy(h_b, d_b, size, cudaMemcpyDeviceToHost);
    
    std::cout &lt;&lt; "\nBackward pass gradients:" &lt;&lt; std::endl;
    
    std::cout &lt;&lt; "Gradient for a:" &lt;&lt; std::endl;
    for (int row = 0; row &lt; n_rows; row++) {
        for (int col = 0; col &lt; n_cols; col++) {
            std::cout &lt;&lt; h_a[row * stride + col] &lt;&lt; " ";
        }
        std::cout &lt;&lt; std::endl;
    }
    
    std::cout &lt;&lt; "\nGradient for b:" &lt;&lt; std::endl;
    for (int row = 0; row &lt; n_rows; row++) {
        for (int col = 0; col &lt; n_cols; col++) {
            std::cout &lt;&lt; h_b[row * stride + col] &lt;&lt; " ";
        }
        std::cout &lt;&lt; std::endl;
    }
    
    cudaFree(d_a);
    cudaFree(d_b);
    cudaFree(d_c);
    cudaFree(d_dc);
    
    return 0;
}
</code></pre>
    </div>

    </div>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-c.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-cpp.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-markdown.min.js"></script>
</body>
</html>